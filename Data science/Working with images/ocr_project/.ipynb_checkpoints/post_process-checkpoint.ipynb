{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f22f9f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, csv\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "def words(text): return re.findall(r'\\w+', text.lower())\n",
    "\n",
    "\n",
    "WORDS = Counter(words(open('ocr_project/words_alpha.txt').read()))\n",
    "\n",
    "def P(word, N=sum(WORDS.values())):\n",
    "    \"Probability of `word`.\"\n",
    "    return WORDS[word] / N\n",
    "\n",
    "\n",
    "def correction(word):\n",
    "    \"Most probable spelling correction for word.\"\n",
    "    return max(candidates(word), key=P)\n",
    "\n",
    "\n",
    "\n",
    "def decode(word):\n",
    "    letters_map = {'@': 'a', '$': 's', '!': 'i', '1': 'l', '0': 'o', '(': 'c', '+': 't'}\n",
    "    symbol_chars = 0\n",
    "    word = list(word.lower())\n",
    "    for i in range(len(word)):\n",
    "        if word[i] in letters_map:\n",
    "            word[i] = letters_map.get(word[i])\n",
    "            symbol_chars += 1\n",
    "    return ''.join(word), symbol_chars\n",
    "\n",
    "\n",
    "def deleteDuplicates(word):\n",
    "    dups_dictionary = {word: 0}\n",
    "    splits = [(word[:i], word[i:]) for i in range(1, len(word))]\n",
    "    deletes = [L + R[1:] for L, R in splits if L[-1] == R[0]]\n",
    "    if len(deletes) > 0:\n",
    "        repeated_chars = 1\n",
    "        dups_dictionary[deletes[0]] = repeated_chars\n",
    "        # Try to remove any other duplicates like removing other o's in shooow\n",
    "        while len(deletes) > 1:\n",
    "            word = list(set(deletes))[0]\n",
    "            splits = [(word[:i], word[i:]) for i in range(1, len(word))]\n",
    "            deletes = [L + R[1:] for L, R in splits if L[-1] == R[0]]\n",
    "            repeated_chars += 1\n",
    "            dups_dictionary[deletes[0]] = repeated_chars\n",
    "        return dups_dictionary\n",
    "    return None\n",
    "\n",
    "\n",
    "def transpose(word):\n",
    "    splits = [(word[:i], word[i:]) for i in range(len(word) + 1)]\n",
    "    transposes = [L + R[1] + R[0] + R[2:] for L, R in splits if len(R) > 1]\n",
    "    return transposes\n",
    "\n",
    "\n",
    "def candidates(word):\n",
    "    \"Generate possible spelling corrections for word.\"\n",
    "    return known([word]) or known(edits1(word)) or known(edits2(word)) or [word]\n",
    "\n",
    "\n",
    "def known(words):\n",
    "    \"The subset of `words` that appear in the dictionary of WORDS.\"\n",
    "    return set(w for w in words if w in WORDS)\n",
    "\n",
    "\n",
    "def edits1(word):\n",
    "    \"All edits that are one edit away from `word`.\"\n",
    "    letters    = 'abcdefghijklmnopqrstuvwxyz'\n",
    "    splits     = [(word[:i], word[i:])    for i in range(len(word) + 1)]\n",
    "    deletes    = [L + R[1:]               for L, R in splits if R]\n",
    "    transposes = [L + R[1] + R[0] + R[2:] for L, R in splits if len(R)>1]\n",
    "    replaces   = [L + c + R[1:]           for L, R in splits if R for c in letters]\n",
    "    inserts    = [L + c + R               for L, R in splits for c in letters]\n",
    "    return set(deletes + transposes + replaces + inserts)\n",
    "\n",
    "\n",
    "def edits2(word):\n",
    "    \"All edits that are two edits away from `word`.\"\n",
    "    return (e2 for e1 in edits1(word) for e2 in edits1(e1))\n",
    "\n",
    "\n",
    "def correct_text(text):\n",
    "    if len(text.split(' ')) > 1:\n",
    "        print('Start of words in \"{}\"'.format(text))\n",
    "        for w in text.split(' '):\n",
    "            print('***',end='')\n",
    "            correct_word(w)\n",
    "        print('End of words in \"{}\"'.format(text))\n",
    "    else:\n",
    "        correct_word(text)\n",
    "\n",
    "def correct_word(word):\n",
    "    original_word = word.lower()\n",
    "    correction_dictionary = {'Original_word': original_word, 'correction':'',\n",
    "                             'symbol_chars': 0, 'repeated_chars': 0, 'swap_chars': 0, 'OOV': 0}\n",
    "    \n",
    "        #Search if the input is exist in the dictionary\n",
    "    if original_word in WORDS:\n",
    "        correction_dictionary['correction'] = original_word\n",
    "        return correction_dictionary\n",
    "    \n",
    "    #Check if the input is a number\n",
    "    if original_word.isdigit():\n",
    "        correction_dictionary['correction'] = original_word\n",
    "        return correction_dictionary\n",
    "    else:\n",
    "        word = original_word\n",
    "    \n",
    "    # Search for symbols, decode them and try correction on decoded word\n",
    "    decoded_word, symbols_count = decode(word)\n",
    "    if symbols_count > 0:\n",
    "        # Try correction after decode\n",
    "        correction_dictionary['symbol_chars'] += symbols_count\n",
    "        if correction(decoded_word) == decoded_word and decoded_word in WORDS:\n",
    "            #correction_dictionary['symbol_chars'] += symbols_count\n",
    "            correction_dictionary['correction'] = decoded_word\n",
    "            return correction_dictionary\n",
    "        # If we still didn't get a match after decode,\n",
    "        # then we will use the decoded word for more analysis\n",
    "        else:\n",
    "            word = decoded_word\n",
    "\n",
    "    # Try deleteDuplicates\n",
    "    if deleteDuplicates(word):\n",
    "        duplicates_dictionary = deleteDuplicates(word)\n",
    "        for trimmed_word in duplicates_dictionary:\n",
    "            if correction(trimmed_word) == trimmed_word and trimmed_word in WORDS:\n",
    "                correction_dictionary['repeated_chars'] += duplicates_dictionary.get(trimmed_word)\n",
    "                correction_dictionary['correction'] = trimmed_word\n",
    "                #print('Input word is: {}, possible match is: {}, {}' \\\n",
    "                 #   .format(original_word, trimmed_word, correction_dictionary))\n",
    "                return correction_dictionary\n",
    "        # If we still didn't get a match after deleteDuplicates,\n",
    "        # then we will use the deleteDuplicates word for more analysis\n",
    "        # if there are trimmed duplicates\n",
    "        if duplicates_dictionary.get(trimmed_word) > 0:\n",
    "            correction_dictionary['repeated_chars'] += duplicates_dictionary.get(trimmed_word)\n",
    "            word = trimmed_word\n",
    "\n",
    "    # Try transpose\n",
    "    \n",
    "    transposes = transpose(word)\n",
    "    for transposed_word in transposes:\n",
    "        if correction(transposed_word) == transposed_word and transposed_word in WORDS:\n",
    "            correction_dictionary['swap_chars'] += 1\n",
    "            correction_dictionary['correction'] = transposed_word\n",
    "            #print('Input word is: {}, possible match is: {}, {}' \\\n",
    "             #   .format(original_word, transposed_word, correction_dictionary))\n",
    "            return correction_dictionary\n",
    "       \n",
    "\n",
    "    # Otherwise, we will match the exact input word\n",
    "    # or the suggested correction of input word\n",
    "    # if it exists in the wordlist\n",
    "    if original_word in WORDS:\n",
    "        correction_dictionary['correction'] = original_word\n",
    "        return correction_dictionary\n",
    "   \n",
    "\n",
    "    \n",
    "    if correction(original_word) in WORDS:\n",
    "        correction_dictionary['correction'] = correction(original_word)\n",
    "        correction_dictionary['symbol_chars'] = 0\n",
    "        correction_dictionary['repeated_chars'] = 0\n",
    "        correction_dictionary['swap_chars'] = 0\n",
    "        correction_dictionary['OOV'] += 1\n",
    "\n",
    "        return correction_dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "328d67da",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['BRITISH',\n",
       " 'COUNCIL',\n",
       " '',\n",
       " ' ',\n",
       " '',\n",
       " 'Questions 3640',\n",
       " 'Complete the summary below,',\n",
       " '',\n",
       " '(Choose NO MORE THAN TWO WORDS from the passage for each answer.',\n",
       " '',\n",
       " 'Wirte your answers in boxes 36-40 on your answer sheet.',\n",
       " '',\n",
       " 'SSobotka ergues that big business and users of helium need to help lack after helium',\n",
       " '',\n",
       " 'stocks because 36 v= wll not be encouraged through buying and seling',\n",
       " '',\n",
       " '‘alone. Richardson believes that the 37.',\n",
       " '',\n",
       " ' ',\n",
       " '',\n",
       " 'needs to be withdrawn, as the',\n",
       " \"U.S. provides most ofthe world's heium, He argues tha righer costs would mean\",\n",
       " 'people have',\n",
       " '',\n",
       " '38 vanes 0 USE He fesouree many times over.',\n",
       " '',\n",
       " 'People should nese a 39 to access helium that we stil have.',\n",
       " '',\n",
       " ' ',\n",
       " '',\n",
       " 'Furthermore, 240... should ensure that helium is used carefully',\n",
       " '',\n",
       " '4',\n",
       " '\\x0c']"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('ocr_project/output.txt', 'r') as word_list:\n",
    "    words = word_list.read().split('\\n')\n",
    "words\n",
    "# print(correct_word(words[0].replace('\\n','')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "2dd8523f",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_words = []\n",
    "for word in words:\n",
    "    n_words.append(word + ' \\n')\n",
    "# n_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "cc622ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_words = []\n",
    "for word in n_words:\n",
    "    processed_words.extend(word.replace('\\x0c', '').replace('(', '').replace('.', ' .').replace(')', '').replace('^', '').split(' '))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "4e81a9b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['BRITISH',\n",
       " '\\n',\n",
       " 'COUNCIL',\n",
       " '\\n',\n",
       " '',\n",
       " '\\n',\n",
       " '',\n",
       " '',\n",
       " '\\n',\n",
       " '',\n",
       " '\\n',\n",
       " 'Questions',\n",
       " '3640',\n",
       " '\\n',\n",
       " 'Complete',\n",
       " 'the',\n",
       " 'summary',\n",
       " 'below,',\n",
       " '\\n',\n",
       " '',\n",
       " '\\n',\n",
       " 'Choose',\n",
       " 'NO',\n",
       " 'MORE',\n",
       " 'THAN',\n",
       " 'TWO',\n",
       " 'WORDS',\n",
       " 'from',\n",
       " 'the',\n",
       " 'passage',\n",
       " 'for',\n",
       " 'each',\n",
       " 'answer',\n",
       " '.',\n",
       " '\\n',\n",
       " '',\n",
       " '\\n',\n",
       " 'Wirte',\n",
       " 'your',\n",
       " 'answers',\n",
       " 'in',\n",
       " 'boxes',\n",
       " '36-40',\n",
       " 'on',\n",
       " 'your',\n",
       " 'answer',\n",
       " 'sheet',\n",
       " '.',\n",
       " '\\n',\n",
       " '',\n",
       " '\\n',\n",
       " 'SSobotka',\n",
       " 'ergues',\n",
       " 'that',\n",
       " 'big',\n",
       " 'business',\n",
       " 'and',\n",
       " 'users',\n",
       " 'of',\n",
       " 'helium',\n",
       " 'need',\n",
       " 'to',\n",
       " 'help',\n",
       " 'lack',\n",
       " 'after',\n",
       " 'helium',\n",
       " '\\n',\n",
       " '',\n",
       " '\\n',\n",
       " 'stocks',\n",
       " 'because',\n",
       " '36',\n",
       " 'v=',\n",
       " 'wll',\n",
       " 'not',\n",
       " 'be',\n",
       " 'encouraged',\n",
       " 'through',\n",
       " 'buying',\n",
       " 'and',\n",
       " 'seling',\n",
       " '\\n',\n",
       " '',\n",
       " '\\n',\n",
       " '‘alone',\n",
       " '.',\n",
       " 'Richardson',\n",
       " 'believes',\n",
       " 'that',\n",
       " 'the',\n",
       " '37',\n",
       " '.',\n",
       " '\\n',\n",
       " '',\n",
       " '\\n',\n",
       " '',\n",
       " '',\n",
       " '\\n',\n",
       " '',\n",
       " '\\n',\n",
       " 'needs',\n",
       " 'to',\n",
       " 'be',\n",
       " 'withdrawn,',\n",
       " 'as',\n",
       " 'the',\n",
       " '\\n',\n",
       " 'U',\n",
       " '.S',\n",
       " '.',\n",
       " 'provides',\n",
       " 'most',\n",
       " 'ofthe',\n",
       " \"world's\",\n",
       " 'heium,',\n",
       " 'He',\n",
       " 'argues',\n",
       " 'tha',\n",
       " 'righer',\n",
       " 'costs',\n",
       " 'would',\n",
       " 'mean',\n",
       " '\\n',\n",
       " 'people',\n",
       " 'have',\n",
       " '\\n',\n",
       " '',\n",
       " '\\n',\n",
       " '38',\n",
       " 'vanes',\n",
       " '0',\n",
       " 'USE',\n",
       " 'He',\n",
       " 'fesouree',\n",
       " 'many',\n",
       " 'times',\n",
       " 'over',\n",
       " '.',\n",
       " '\\n',\n",
       " '',\n",
       " '\\n',\n",
       " 'People',\n",
       " 'should',\n",
       " 'nese',\n",
       " 'a',\n",
       " '39',\n",
       " 'to',\n",
       " 'access',\n",
       " 'helium',\n",
       " 'that',\n",
       " 'we',\n",
       " 'stil',\n",
       " 'have',\n",
       " '.',\n",
       " '\\n',\n",
       " '',\n",
       " '\\n',\n",
       " '',\n",
       " '',\n",
       " '\\n',\n",
       " '',\n",
       " '\\n',\n",
       " 'Furthermore,',\n",
       " '240',\n",
       " '.',\n",
       " '.',\n",
       " '.',\n",
       " 'should',\n",
       " 'ensure',\n",
       " 'that',\n",
       " 'helium',\n",
       " 'is',\n",
       " 'used',\n",
       " 'carefully',\n",
       " '\\n',\n",
       " '',\n",
       " '\\n',\n",
       " '4',\n",
       " '\\n',\n",
       " '',\n",
       " '\\n']"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "5f39d5b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 181/181 [00:04<00:00, 40.55it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "corrected_words = []\n",
    "\n",
    "for i in tqdm(processed_words):\n",
    "    try:\n",
    "        if i == '':\n",
    "            continue\n",
    "        if i == '\\n':\n",
    "            corrected_words.append('\\n')\n",
    "            continue\n",
    "        if i == '.':\n",
    "            corrected_words.append('.')\n",
    "            continue\n",
    "        if i.isupper():\n",
    "            corrected_words.append(correct_word(i)['correction'].upper())\n",
    "            continue\n",
    "        if not i.islower():\n",
    "            corrected_words.append(correct_word(i)['correction'].capitalize())\n",
    "            continue\n",
    "        corrected_words.append(correct_word(i)['correction'])\n",
    "    except:\n",
    "        corrected_words.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "e22fc6ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['BRITISH',\n",
       " '\\n',\n",
       " 'COUNCIL',\n",
       " '\\n',\n",
       " '\\n',\n",
       " '\\n',\n",
       " '\\n',\n",
       " 'Questions',\n",
       " '3640',\n",
       " '\\n',\n",
       " 'Complete',\n",
       " 'the',\n",
       " 'summary',\n",
       " 'below',\n",
       " '\\n',\n",
       " '\\n',\n",
       " 'Choose',\n",
       " 'NO',\n",
       " 'MORE',\n",
       " 'THAN',\n",
       " 'TWO',\n",
       " 'WORDS',\n",
       " 'from',\n",
       " 'the',\n",
       " 'passage',\n",
       " 'for',\n",
       " 'each',\n",
       " 'answer',\n",
       " '.',\n",
       " '\\n',\n",
       " '\\n',\n",
       " 'Write',\n",
       " 'your',\n",
       " 'answers',\n",
       " 'in',\n",
       " 'boxes',\n",
       " '36-40',\n",
       " 'on',\n",
       " 'your',\n",
       " 'answer',\n",
       " 'sheet',\n",
       " '.',\n",
       " '\\n',\n",
       " '\\n',\n",
       " 'SSobotka',\n",
       " 'argues',\n",
       " 'that',\n",
       " 'big',\n",
       " 'business',\n",
       " 'and',\n",
       " 'users',\n",
       " 'of',\n",
       " 'helium',\n",
       " 'need',\n",
       " 'to',\n",
       " 'help',\n",
       " 'lack',\n",
       " 'after',\n",
       " 'helium',\n",
       " '\\n',\n",
       " '\\n',\n",
       " 'stocks',\n",
       " 'because',\n",
       " '36',\n",
       " 'vd',\n",
       " 'wl',\n",
       " 'not',\n",
       " 'be',\n",
       " 'encouraged',\n",
       " 'through',\n",
       " 'buying',\n",
       " 'and',\n",
       " 'seling',\n",
       " '\\n',\n",
       " '\\n',\n",
       " 'alone',\n",
       " '.',\n",
       " 'Richardson',\n",
       " 'believes',\n",
       " 'that',\n",
       " 'the',\n",
       " '37',\n",
       " '.',\n",
       " '\\n',\n",
       " '\\n',\n",
       " '\\n',\n",
       " '\\n',\n",
       " 'needs',\n",
       " 'to',\n",
       " 'be',\n",
       " 'withdrawn',\n",
       " 'as',\n",
       " 'the',\n",
       " '\\n',\n",
       " 'U',\n",
       " 'HS',\n",
       " '.',\n",
       " 'provides',\n",
       " 'most',\n",
       " 'cothe',\n",
       " 'worlds',\n",
       " 'heaume',\n",
       " 'He',\n",
       " 'argues',\n",
       " 'tha',\n",
       " 'wigher',\n",
       " 'costs',\n",
       " 'would',\n",
       " 'mean',\n",
       " '\\n',\n",
       " 'people',\n",
       " 'have',\n",
       " '\\n',\n",
       " '\\n',\n",
       " '38',\n",
       " 'vanes',\n",
       " '0',\n",
       " 'USE',\n",
       " 'He',\n",
       " 'resource',\n",
       " 'many',\n",
       " 'times',\n",
       " 'over',\n",
       " '.',\n",
       " '\\n',\n",
       " '\\n',\n",
       " 'People',\n",
       " 'should',\n",
       " 'nese',\n",
       " 'a',\n",
       " '39',\n",
       " 'to',\n",
       " 'access',\n",
       " 'helium',\n",
       " 'that',\n",
       " 'we',\n",
       " 'stilb',\n",
       " 'have',\n",
       " '.',\n",
       " '\\n',\n",
       " '\\n',\n",
       " '\\n',\n",
       " '\\n',\n",
       " 'Furthermore',\n",
       " '240',\n",
       " '.',\n",
       " '.',\n",
       " '.',\n",
       " 'should',\n",
       " 'ensure',\n",
       " 'that',\n",
       " 'helium',\n",
       " 'is',\n",
       " 'used',\n",
       " 'carefully',\n",
       " '\\n',\n",
       " '\\n',\n",
       " '4',\n",
       " '\\n',\n",
       " '\\n']"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corrected_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "04d90e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('your_file.txt', 'w') as f:\n",
    "    for item in corrected_words:\n",
    "        if item == '.':\n",
    "            f.write(item)\n",
    "        else:\n",
    "            f.write(' ' + item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "d310cee0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Original_word': '`alone',\n",
       " 'correction': 'alone',\n",
       " 'symbol_chars': 0,\n",
       " 'repeated_chars': 0,\n",
       " 'swap_chars': 0,\n",
       " 'OOV': 1}"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_word('`alone')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "866e1eee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
